{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import colors\n",
    "# from PIL import Image\n",
    "import pandas as pd\n",
    "import collections\n",
    "from linecache import getline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import pickle\n",
    "import seaborn as sn\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (20,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Venice Water Level Dataset from 1983 to 2015\n",
    "dataframe = pd.read_csv('./lstm-flood/dataset/venezia.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "dataset   = dataframe.values\n",
    "dataset   = dataset.astype('float32')\n",
    "dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_levels = dataframe['level'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_levels = []\n",
    "                 \n",
    "for i in water_levels:\n",
    "    if i >= 0:\n",
    "        cleaned_levels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame(cleaned_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler  = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "\n",
    "percentage_train = 0.80\n",
    "\n",
    "train_size  = int(len(dataset) * percentage_train)\n",
    "test_size   = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(\"Training Datapoints :\", len(train), \"testing Datapoints :\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Training Data ---', percentage_train * 100, '% ---')\n",
    "plt.plot(train)\n",
    "plt.show()\n",
    "print('--- Test Data ---', 100-(percentage_train * 100), '% ---')\n",
    "plt.plot(test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a sliding window of the dataset.\n",
    "# applying a window or batch of dataset make batched features dataset\n",
    "# converting a problem in a nested loop, to reduce the time complexity.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LSTMs do not require a sliding window of inputs. They can remember what they have seen in the past, and if you feed in training examples one at a time they will choose the right size window of inputs to remember on their own.\n",
    "\n",
    "LSTM's are already prone to overfitting, and if you feed in lots of redundant data with a sliding window then yes, they are likely to overfit.\n",
    "On the other hand, a sliding window is necessary for time series forecasting with Feedforward Neural Networks, because FNNs require a fixed size input and do not have memory, so this is the most natural way to feed them time series data.\n",
    "Whether or not the FNN will overfit depends on its architecture and your data, but all standard regularization techniques will apply if it does. For example you can try choosing a smaller network, L2 regularization, Dropout, etc.\n",
    "\"\"\"\n",
    "# in simple words cutting down the data into chunks of data.\n",
    "def create_dataset(dataset, sliding_window=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-sliding_window-1):\n",
    "        a = dataset[i:(i+sliding_window), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + sliding_window, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a n-24 sliding window equivalent to 24 hours of historical data - original 10\n",
    "slide_window   = 24\n",
    "trainX, trainY = create_dataset(train, slide_window)\n",
    "testX, testY   = create_dataset(test, slide_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX  = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "np.shape(testX)\n",
    "print(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_dim=slide_window))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# Epoch size 50\n",
    "model.fit(trainX, trainY, nb_epoch=50, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the evaluation for both the\n",
    "import math\n",
    "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
    "trainScore = math.sqrt(trainScore)\n",
    "trainScore = scaler.inverse_transform(np.array([[trainScore]]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = model.evaluate(testX, testY, verbose=0)\n",
    "testScore = math.sqrt(testScore)\n",
    "testScore = scaler.inverse_transform(np.array([[testScore]]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "  \n",
    "# Save the trained model as a pickle string. \n",
    "saved_model = pickle.dumps(model) \n",
    "  \n",
    "# Load the pickled model \n",
    "model_from_pickle = pickle.loads(saved_model) \n",
    "  \n",
    "# Use the loaded pickled model to make predictions \n",
    "model_from_pickle.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict_list = [1] * 24\n",
    "# print(to_predict_list)\n",
    "to_predict = np.array(to_predict_list).reshape(1, 1, 24)\n",
    "print(to_predict)\n",
    "loaded_model = pickle.load(open(\"./filename.pkl\", \"rb\"))\n",
    "result = loaded_model.predict(to_predict)\n",
    "result = str(result[0][0])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
